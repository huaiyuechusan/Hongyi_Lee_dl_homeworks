{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  &#x1F4D1; **作业 15: Meta Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug  4 17:57:13 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.33                 Driver Version: 546.33       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   44C    P8               4W /  50W |   1789MiB /  4096MiB |     16%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2920    C+G   G:\\Soda Music\\1.6.9\\SodaMusic.exe         N/A      |\n",
      "|    0   N/A  N/A      4980    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      5980    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      6068    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      6576    C+G   G:\\QQNT\\QQ.exe                            N/A      |\n",
      "|    0   N/A  N/A      8980    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A      9640    C+G   ...ogram Files (x86)\\Typora\\Typora.exe    N/A      |\n",
      "|    0   N/A  N/A     10096    C+G   ...3\\extracted\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     14084    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15340    C+G   ...on\\wallpaper_engine\\wallpaper32.exe    N/A      |\n",
      "|    0   N/A  N/A     15624    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     16940    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     30940    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     31012    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Download Data\n",
    "运行单元下载数据，这些数据已经被TAs预处理。\n",
    "数据集已经增强，因此不需要额外的数据增强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workspace_dir = '.'\n",
    "\n",
    "# # Download dataset\n",
    "# !wget https://github.com/xraychen/shiny-disco/releases/download/Latest/omniglot.tar.gz \\\n",
    "#     -O \"{workspace_dir}/Omniglot.tar.gz\"\n",
    "# !wget https://github.com/xraychen/shiny-disco/releases/download/Latest/omniglot-test.tar.gz \\\n",
    "#     -O \"{workspace_dir}/Omniglot-test.tar.gz\"\n",
    "\n",
    "# # Use `tar' command to decompress\n",
    "# !tar -zxf \"{workspace_dir}/Omniglot.tar.gz\" -C \"{workspace_dir}/\"\n",
    "# !tar -zxf \"{workspace_dir}/Omniglot-test.tar.gz\" -C \"{workspace_dir}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = cuda\n",
      "Set env random_seed = 0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"DEVICE = {device}\")\n",
    "\n",
    "def all_seed(seed=6666):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # CPU\n",
    "    torch.manual_seed(seed)\n",
    "    # GPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    # python全局\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # cudnn\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    print(f'Set env random_seed = {seed}')\n",
    "\n",
    "all_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建准备工作\n",
    "\n",
    "由于我们的任务是图像分类，我们需要**建立一个基于CNN的模型**。   \n",
    "然而，要实现MAML算法，**我们需要调整“nn.Module”中的一些代码。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAML伪代码\n",
    "\n",
    "![](./pic/MAML.jpg)\n",
    "\n",
    "在第10行, 我们希望使用初始$\\theta$(<font color=\"#0CC\">**模型初始参数**</font> )进行梯度下降（会存在二阶导， 梯度计算可以看第8行），\n",
    "\n",
    "所以在<font color=\"#0C0\">**循环内**</font>（第7行）\n",
    "- 我们构建连续梯度图`torch.autograd.grad(loss, fast_weights.values(), create_graph=True)`\n",
    "- 并用`functional_forward`进行推理，手动实现SGD进行更新参数，而不是用`forward`和`backward` \n",
    "- 当我们采用`First-order approximation`的时候，直接将连续梯度图关闭就行\n",
    "  - 即`torch.autograd.grad(loss, fast_weights.values(), create_graph=False)` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: 模型块定义`Model block definition`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(in_ch: int, out_ch: int):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "        nn.BatchNorm2d(out_ch),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    )\n",
    "\n",
    "\n",
    "# 利用指定权重进行foward\n",
    "def ConvBlockFunction(x, w, b, w_bn, b_bn):\n",
    "    x = F.conv2d(x, w, b, padding=1)\n",
    "    x = F.batch_norm(\n",
    "        x, running_mean=None, running_var=None, weight=w_bn, bias=b_bn, training=True\n",
    "    )\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_ch, k_way):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = ConvBlock(in_ch, 64)\n",
    "        self.conv2 = ConvBlock(64, 64)\n",
    "        self.conv3 = ConvBlock(64, 64)\n",
    "        self.conv4 = ConvBlock(64, 64)\n",
    "        self.logits = nn.Linear(64, k_way)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "    def functional_forward(self, x, params):\n",
    "        \"\"\"\n",
    "        使用指定参数进行推理\n",
    "        params:\n",
    "            x: 输入图片 [batch, 1, 28, 28]\n",
    "            params: OrderedDict 模型参数,\n",
    "                i.e. 卷积层的 weights 和 biases 与 `batch normalization`的 weights 和 biases\n",
    "        \"\"\"\n",
    "        for block in [1, 2, 3, 4]:\n",
    "            x = ConvBlockFunction(\n",
    "                x,\n",
    "                params[f\"conv{block}.0.weight\"],\n",
    "                params[f\"conv{block}.0.bias\"],\n",
    "                params.get(f\"conv{block}.1.weight\"),\n",
    "                params.get(f\"conv{block}.1.bias\"),\n",
    "            )\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.linear(x, params[\"logits.weight\"], params[\"logits.bias\"])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: 创建标签**\n",
    "\n",
    "`create_label` 用于创建标签\n",
    "\n",
    "对于`N-way K-shot few-shot`分类问题中,\n",
    "- `n_way`  表示n个类别, \n",
    "- `k_shot` K表示每个类的样本数.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_label(n_way, k_shot):\n",
    "    return torch.arange(n_way).repeat_interleave(k_shot).long()\n",
    "\n",
    "create_label(5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: 计算`Accuracy`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(logits, labels):\n",
    "    \"\"\"utility function for accuracy calculation\"\"\"\n",
    "    acc = np.asarray(\n",
    "        # 使用 torch.argmax 找到每个维度的最大值索引\n",
    "        # 在给定的 logits 张量中找到最后一维（通常是类别概率）的最大值所在的索引\n",
    "        [(torch.argmax(logits, -1).cpu().numpy() == labels.cpu().numpy())]\n",
    "    ).mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4: 定义 Dataset**\n",
    "\n",
    "`dataset` 返回随机抽取的一个类型的 (`k_shot + q_query`)张图片\n",
    "\n",
    "返回张量的大小为： `[k_shot + q_query, 1, 28, 28]`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'E:\\leedl-tutorial\\Homework\\HW15_MetaLearning\\omniglot'\n",
    "train_data_path = f\"{data_dir}/Omniglot/images_background/\"\n",
    "file_list = [\n",
    "            f for f in glob.glob(train_data_path + \"**/character*\", recursive=True)\n",
    "        ]\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character01',\n",
       " 'E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character02',\n",
       " 'E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character03',\n",
       " 'E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character04',\n",
       " 'E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character05',\n",
       " 'E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character06',\n",
       " 'E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character07',\n",
       " 'E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character08',\n",
       " 'E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character09',\n",
       " 'E:\\\\leedl-tutorial\\\\Homework\\\\HW15_MetaLearning\\\\omniglot/Omniglot/images_background\\\\Alphabet_of_the_Magi.0\\\\character10']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Omniglot(Dataset):\n",
    "    def __init__(self, data_dir, k_shot, q_query, task_num=None):\n",
    "        # 路径tree如下\n",
    "        #         ../input/ml2022spring-hw15/omniglot/Omniglot/images_background\n",
    "        #         ├── Alphabet_of_the_Magi.0\n",
    "        #         │   ├── character01\n",
    "        #         │   │   ├── 0709_01.png\n",
    "        #         │   │   ├── 0709_02.png\n",
    "        #         │   │   ├── ...\n",
    "        #         │   ├── character02\n",
    "        #         │   │   ├── 0710_01.png\n",
    "        #         │   │   ├── 0710_02.png\n",
    "        #         │   │   ├── ...\n",
    "        #         │   ├── character03\n",
    "        #         │   │   ├── 0711_01.png\n",
    "        #         │   │   ├── 0711_02.png\n",
    "        #         │   │   ├── ...\n",
    "        # 获取所有classifier :  dir/[type]/character[x]\n",
    "        self.file_list = [\n",
    "            f for f in glob.glob(data_dir + \"**/character*\", recursive=True)\n",
    "        ]\n",
    "        # 限制 task_num 数量的classifier\n",
    "        if task_num is not None:\n",
    "            self.file_list = self.file_list[: min(len(self.file_list), task_num)]\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        # 输出\n",
    "        self.n = k_shot + q_query\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 取其中的一个 classifier\n",
    "        img_path = self.file_list[idx]\n",
    "        img_list = [f for f in glob.glob(img_path + \"**/*.png\", recursive=True)]\n",
    "        img_list.sort()\n",
    "        imgs = [self.transform(Image.open(img_file)) for img_file in img_list]\n",
    "        \n",
    "        # 每个 classifier 随机抽取 `k_shot + q_query` 张img\n",
    "        sample = np.arange(20)\n",
    "        np.random.shuffle(sample)\n",
    "        random_idx_list = sample[:self.n]\n",
    "        imgs = torch.stack(imgs)[random_idx_list]\n",
    "        return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &#x2728; **Step 5: 算法实现`Learning Algorithms`**\n",
    "\n",
    "### 迁移学习`Transfer learning`\n",
    "\n",
    "`BaseSolver`首先会从训练集中抽取5个任务， 然后在5个任务上依次进行正常的分类器训练。  \n",
    "在推理阶段，模型在`support`样本上进行`inner_train_step`微调， 然后在`query`数据上进行推理  \n",
    "为了与元学习(`meta learning`)求解器保持一致，基础求解器具有与元学习解算器完全相同的输入和输出格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BaseSolver(\n",
    "    model,\n",
    "    optimizer,\n",
    "    x,\n",
    "    n_way,\n",
    "    k_shot,\n",
    "    q_query,\n",
    "    loss_fn,\n",
    "    inner_train_step=1,\n",
    "    inner_lr=0.4,\n",
    "    train=True,\n",
    "    return_labels=False,\n",
    "):\n",
    "    criterion, task_loss, task_acc = loss_fn, [], []\n",
    "    labels = []\n",
    "\n",
    "    for meta_batch in x:\n",
    "        # 获取数据 \n",
    "        support_set = meta_batch[: n_way * k_shot]\n",
    "        query_set = meta_batch[n_way * k_shot :]\n",
    "\n",
    "        if train:\n",
    "            \"\"\" training loop \"\"\"\n",
    "            # 使用support set计算损失\n",
    "            labels = create_label(n_way, k_shot).to(device)\n",
    "            logits = model.forward(support_set)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            task_loss.append(loss)\n",
    "            task_acc.append(calculate_accuracy(logits, labels))\n",
    "        else:\n",
    "            \"\"\" validation / testing loop \"\"\"\n",
    "            # 用 support set 图片进行 `inner_train_step` 微调\n",
    "            fast_weights = OrderedDict(model.named_parameters())\n",
    "            for inner_step in range(inner_train_step):\n",
    "                train_label = create_label(n_way, k_shot).to(device)\n",
    "                logits = model.functional_forward(support_set, fast_weights)\n",
    "                loss = criterion(logits, train_label)\n",
    "\n",
    "                grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n",
    "                # Perform SGD\n",
    "                fast_weights = OrderedDict(\n",
    "                    (name, param - inner_lr * grad)\n",
    "                    for ((name, param), grad) in zip(fast_weights.items(), grads)\n",
    "                )\n",
    "\n",
    "            if not return_labels:\n",
    "                \"\"\" validation \"\"\"\n",
    "                val_label = create_label(n_way, q_query).to(device)\n",
    "\n",
    "                logits = model.functional_forward(query_set, fast_weights)\n",
    "                loss = criterion(logits, val_label)\n",
    "                task_loss.append(loss)\n",
    "                task_acc.append(calculate_accuracy(logits, val_label))\n",
    "            else:\n",
    "                \"\"\" testing \"\"\"\n",
    "                logits = model.functional_forward(query_set, fast_weights)\n",
    "                labels.extend(torch.argmax(logits, -1).cpu().numpy())\n",
    "\n",
    "    if return_labels:\n",
    "        return labels\n",
    "\n",
    "    batch_loss = torch.stack(task_loss).mean()\n",
    "    task_acc = np.mean(task_acc)\n",
    "\n",
    "    if train:\n",
    "        # 更新model\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return batch_loss, task_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#x2728; Meta Learning\n",
    "\n",
    "这里是Meta Learning algorithm的主要实现  \n",
    "<font color=darkred><b>TODO: </font></b>\n",
    "- <font color=darkred>实现`First Order MAML`, </font>可以参考[p.25 of the slides](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pdf#page=25&view=FitW).\n",
    "- <font color=darkred>实现一般的`original MAML`, </font>可以参考[the slides of meta learning (p.13 ~ p.18)](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pdf#page=13&view=FitW).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetaSolver(\n",
    "    model,\n",
    "    optimizer,\n",
    "    x,\n",
    "    n_way,\n",
    "    k_shot,\n",
    "    q_query,\n",
    "    loss_fn,\n",
    "    inner_train_step=1,\n",
    "    inner_lr=0.4,\n",
    "    train=True,\n",
    "    return_labels=False,\n",
    "    FO=False\n",
    "):\n",
    "    criterion, task_loss, task_acc = loss_fn, [], []\n",
    "    labels = []\n",
    "\n",
    "    for meta_batch in x:\n",
    "        # 获取数据\n",
    "        support_set = meta_batch[: n_way * k_shot]\n",
    "        query_set = meta_batch[n_way * k_shot :]\n",
    "        # 没有training loop \n",
    "        # 复制原始参数\n",
    "        fast_weights = OrderedDict(model.named_parameters())\n",
    "        ### ---------- INNER TRAIN LOOP ---------- ###\n",
    "        # support_set 进行1step训练： 关注梯度——一阶导\n",
    "        for inner_step in range(inner_train_step):\n",
    "            train_label = create_label(n_way, k_shot).to(device)\n",
    "            logits = model.functional_forward(support_set, fast_weights)\n",
    "            loss = criterion(logits, train_label)\n",
    "            \"\"\" Inner Loop Update \"\"\"\n",
    "            # TODO: 这里实现MAML\n",
    "            grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=not FO) # 便于进行二阶导\n",
    "            fast_weights = OrderedDict(\n",
    "                (name, param - inner_lr * (grad.detach().data if FO else grad) )\n",
    "                for ((name, param), grad) in zip(fast_weights.items(), grads)\n",
    "            )\n",
    "\n",
    "        ### ---------- INNER VALID LOOP ---------- ###\n",
    "        if not return_labels:\n",
    "            \"\"\" training / validation \"\"\"\n",
    "            # query_set 进行测试： 关注loss——二阶导\n",
    "            val_label = create_label(n_way, q_query).to(device)\n",
    "            logits = model.functional_forward(query_set, fast_weights)\n",
    "            loss = criterion(logits, val_label)\n",
    "            task_loss.append(loss)\n",
    "            task_acc.append(calculate_accuracy(logits, val_label))\n",
    "        else:\n",
    "            \"\"\" testing \"\"\"\n",
    "            logits = model.functional_forward(query_set, fast_weights)\n",
    "            labels.extend(torch.argmax(logits, -1).cpu().numpy())\n",
    "\n",
    "    if return_labels:\n",
    "        return labels\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    meta_batch_loss = torch.stack(task_loss).mean()\n",
    "    task_acc = np.mean(task_acc)\n",
    "    if train:\n",
    "        \"\"\" Outer Loop Update \"\"\"\n",
    "        # TODO: 二阶梯度方向传播\n",
    "        meta_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return meta_batch_loss, task_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6: 初始化**\n",
    "\n",
    "模型及数据初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_way = 5\n",
    "k_shot = 1\n",
    "q_query = 1\n",
    "train_inner_train_step = 1\n",
    "val_inner_train_step = 3\n",
    "inner_lr = 0.4\n",
    "meta_lr = 0.001\n",
    "meta_batch_size = 32\n",
    "max_epoch = 30\n",
    "eval_batches = 20\n",
    "data_dir = 'E:\\leedl-tutorial\\Homework\\HW15_MetaLearning\\omniglot'\n",
    "train_data_path = f\"{data_dir}/Omniglot/images_background/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_init(datasets, shuffle=True, num_workers=2):\n",
    "    train_set, val_set = datasets\n",
    "    # 这里batch_size设置成n_way\n",
    "    # 返回 [n_way, k_shot + q_query, 1, 28, 28]\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=n_way,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=n_way, num_workers=num_workers, shuffle=shuffle, drop_last=True\n",
    "    )\n",
    "\n",
    "    train_iter = iter(train_loader)\n",
    "    val_iter = iter(val_loader)\n",
    "    return (train_loader, val_loader), (train_iter, val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & optimizer 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    meta_model = Classifier(1, n_way).to(device)\n",
    "    optimizer = torch.optim.Adam(meta_model.parameters(), lr=meta_lr)\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    return meta_model, optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取`meta-batch`方法\n",
    "\n",
    "主要的作用是将 `[n_way, k_shot+q_query, 1, 28, 28]` 转变成\n",
    "`[n_way*k_shot + n_way*q_query, 1, 28, 28]` 便于在Solver中拆分成 `support_set` 和 `query_set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_batch(meta_batch_size, k_shot, q_query, data_loader, iterator):\n",
    "    \"\"\"\n",
    "    主要的作用是将 [n_way, k_shot+q_query, 1, 28, 28] 转变成\n",
    "    [n_way*k_shot + n_way*q_query, 1, 28, 28] 便于在Solver中拆分成 support_set 和 query_set\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for _ in range(meta_batch_size):\n",
    "        try:\n",
    "            # 一个 \"task_data\" 张量代表 一个task的data: 大小为 [n_way, k_shot+q_query, 1, 28, 28]\n",
    "            task_data = next(iterator)\n",
    "        except StopIteration:\n",
    "            iterator = iter(data_loader)\n",
    "            task_data = next(iterator) \n",
    "        train_data = task_data[:, :k_shot].reshape(-1, 1, 28, 28)\n",
    "        val_data = task_data[:, k_shot:].reshape(-1, 1, 28, 28)\n",
    "        task_data = torch.cat((train_data, val_data), 0)\n",
    "        data.append(task_data)\n",
    "    return torch.stack(data).to(device), iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#x2728; **训练与测试**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "- `solver = 'base'`: 迁移学习(` transfer learning algorithm.`)\n",
    "- `solver = 'meta'`: 元学习(`meta learning algorithm`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use MAML & f_max_epoch=30 & meta_lr=0.001\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "meta_lr_org = meta_lr = 0.001\n",
    "solver = 'meta' # base, meta\n",
    "FO = False\n",
    "meta_model, optimizer, loss_fn = model_init()\n",
    "\n",
    "# 基于solver初始化训练数据\n",
    "if solver == 'base':\n",
    "    f_max_epoch = 5 # the base solver 只用 5 epochs\n",
    "    meta_lr = meta_lr_org\n",
    "    print(f'use transferLearning & f_max_epoch={f_max_epoch} & meta_lr={meta_lr}')\n",
    "    Solver = BaseSolver\n",
    "    train_set, val_set = torch.utils.data.random_split(\n",
    "        Omniglot(train_data_path, k_shot, q_query, task_num=10), [5, 5]\n",
    "    )\n",
    "    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set), shuffle=False)\n",
    "\n",
    "elif solver == 'meta':\n",
    "    f_max_epoch = max_epoch\n",
    "    meta_lr = meta_lr_org\n",
    "    if FO:\n",
    "        f_max_epoch = 40\n",
    "        meta_lr = 0.0014\n",
    "        print(f'use FO-MAML & f_max_epoch={f_max_epoch} & meta_lr={meta_lr}')\n",
    "    else:\n",
    "        print(f'use MAML & f_max_epoch={f_max_epoch} & meta_lr={meta_lr}')\n",
    "    \n",
    "    Solver = partial(MetaSolver, FO=FO)\n",
    "    dataset = Omniglot(train_data_path, k_shot, q_query)\n",
    "    train_split = int(0.8 * len(dataset))\n",
    "    val_split = len(dataset) - train_split\n",
    "    train_set, val_set = torch.utils.data.random_split(\n",
    "        dataset, [train_split, val_split]\n",
    "    )\n",
    "    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set))\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "train_bar = tqdm(range(f_max_epoch))\n",
    "for epoch in train_bar:\n",
    "    train_bar.set_description(f\"[ Epoch {epoch+1:02d}/{f_max_epoch:02d} ]\")\n",
    "    train_meta_loss = []\n",
    "    train_acc = []\n",
    "    # The \"step\" here is a meta-gradinet update step\n",
    "    for step in tqdm(range(max(1, len(train_loader) // meta_batch_size))):\n",
    "        x, train_iter = get_meta_batch(\n",
    "            meta_batch_size, k_shot, q_query, train_loader, train_iter\n",
    "        )\n",
    "        meta_loss, acc = Solver(\n",
    "            meta_model,\n",
    "            optimizer,\n",
    "            x,\n",
    "            n_way,\n",
    "            k_shot,\n",
    "            q_query,\n",
    "            loss_fn, \n",
    "            inner_train_step=train_inner_train_step\n",
    "        )\n",
    "        train_meta_loss.append(meta_loss.item())\n",
    "        train_acc.append(acc)\n",
    "\n",
    "    print(\"--\"*25, f'{epoch+1:02d}', \"--\"*25)\n",
    "    print(\"  Loss    : \", \"%.3f\" % (np.mean(train_meta_loss)), end=\"\\t\")\n",
    "    print(\"  Accuracy: \", \"%.3f %%\" % (np.mean(train_acc) * 100))\n",
    "\n",
    "    # 每个epoch训练完后查看验证集的表现(validation accuracy)  \n",
    "    # 同样也可以在验证集验证的后实现`Early stopping` (可以参考 HW01 中的实现)\n",
    "    val_acc = []\n",
    "    val_loss = []\n",
    "    for eval_step in range(max(1, len(val_loader) // (eval_batches))):\n",
    "        x, val_iter = get_meta_batch(\n",
    "            eval_batches, k_shot, q_query, val_loader, val_iter\n",
    "        )\n",
    "        # test的时候进行 3次inner steps 更新参数\n",
    "        val_loss_i, acc = Solver(\n",
    "            meta_model,\n",
    "            optimizer,\n",
    "            x,\n",
    "            n_way,\n",
    "            k_shot,\n",
    "            q_query,\n",
    "            loss_fn,\n",
    "            inner_train_step=val_inner_train_step,\n",
    "            train=False,\n",
    "        )\n",
    "        val_acc.append(acc)\n",
    "        val_loss.append(val_loss_i.item())\n",
    "\n",
    "    train_bar.set_postfix({\n",
    "        \"trainLoss\": \"%.3f\" % (np.mean(train_meta_loss)),\n",
    "        \"trainAccuracy\": \"%.3f %%\" % (np.mean(train_acc) * 100),\n",
    "        \"valLoss\": \"%.3f\" % (np.mean(val_loss)),\n",
    "        \"valAccuracy\": \"%.3f %%\" % (np.mean(val_acc) * 100)\n",
    "    })\n",
    "    print(\"**\"*25)\n",
    "    print(\"  Validation accuracy: \", \"%.3f %%\" % (np.mean(val_acc) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试和结果输出\n",
    "\n",
    "由于测试数据是由TA提前采样的，因此不应更改“OmnigloTest”数据集中的代码，否则在Kaggle排行榜上的分数可能不正确。  \n",
    "\n",
    "但是，可以随意更改变量`inner_train_step`来设置`query`集图像上的训练步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class OmniglotTest(Dataset):\n",
    "    def __init__(self, test_dir):\n",
    "        self.test_dir = test_dir\n",
    "        self.n = 5\n",
    "\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        support_files = [\n",
    "            os.path.join(self.test_dir, \"support\", f\"{idx:>04}\", f\"image_{i}.png\")\n",
    "            for i in range(self.n)\n",
    "        ]\n",
    "        query_files = [\n",
    "            os.path.join(self.test_dir, \"query\", f\"{idx:>04}\", f\"image_{i}.png\")\n",
    "            for i in range(self.n)\n",
    "        ]\n",
    "\n",
    "        support_imgs = torch.stack(\n",
    "            [self.transform(Image.open(e)) for e in support_files]\n",
    "        )\n",
    "        query_imgs = torch.stack([self.transform(Image.open(e)) for e in query_files])\n",
    "\n",
    "        return support_imgs, query_imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(os.path.join(self.test_dir, \"support\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inner_train_step = 10 # 可以更改这里\n",
    "\n",
    "test_batches = 20\n",
    "test_data_path = 'E:\\leedl-tutorial\\Homework\\HW15_MetaLearning\\omniglot-test\\Omniglot-test'\n",
    "test_dataset = OmniglotTest(test_data_path)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batches, shuffle=False)\n",
    "\n",
    "output = []\n",
    "for _, batch in enumerate(tqdm(test_loader)):\n",
    "    support_set, query_set = batch\n",
    "    x = torch.cat([support_set, query_set], dim=1)\n",
    "    x = x.to(device)\n",
    "\n",
    "    labels = Solver(\n",
    "        meta_model,\n",
    "        optimizer,\n",
    "        x,\n",
    "        n_way,\n",
    "        k_shot,\n",
    "        q_query,\n",
    "        loss_fn,\n",
    "        inner_train_step=test_inner_train_step,\n",
    "        train=False,\n",
    "        return_labels=True,\n",
    "    )\n",
    "\n",
    "    output.extend(labels)\n",
    "\n",
    "# 写入 csv\n",
    "with open(\"output.csv\", \"w\") as f:\n",
    "    f.write(f\"id,class\\n\")\n",
    "    for i, label in enumerate(output):\n",
    "        f.write(f\"{i},{label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **参考**\n",
    "1. Chelsea Finn, Pieter Abbeel, & Sergey Levine. (2017). [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.](https://arxiv.org/abs/1909.09157)\n",
    "1. Aniruddh Raghu, Maithra Raghu, Samy Bengio, & Oriol Vinyals. (2020). [Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML.](https://arxiv.org/abs/1909.09157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

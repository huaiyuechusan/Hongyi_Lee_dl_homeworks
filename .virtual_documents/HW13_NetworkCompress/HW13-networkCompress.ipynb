








!pip install torchsummary


import numpy as np
import pandas as pd
import torch
import os
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset # "ConcatDataset" 和 "Subset" 有可能使用
from torchvision.datasets import DatasetFolder, VisionDataset
from torchsummary import summary
# from tqdm.auto import tqdm
from tqdm import tqdm
import random

# 查看GPU
!nvidia-smi





def all_seed(seed=6666, env=None):
    if env is not None:
        env.seed(seed)
        env.action_space.seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    # CPU
    torch.manual_seed(seed)
    # GPU
    if torch.cuda.is_available():
        
        torch.cuda.manual_seed_all(seed)
        torch.cuda.manual_seed(seed)
    # python全局
    os.environ['PYTHONHASHSEED'] = str(seed)
    # cudnn
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.enabled = False
    print(f'Set env random_seed = {seed}')


cfg = {
    'dataset_root': 'E:\deeplearning_dataset\\food11-hw13',
    'save_dir': './outputs',
    'exp_name': "simple_baseline",
    'batch_size': 64,
    'lr': 5e-4,
    'seed': 20220013,
    'loss_fn_type': 'KD', # simple baseline: CE, medium baseline: KD.
    'weight_decay': 0, #1e-5,
    'grad_norm_max': 10,
    'n_epochs': 20, # 训练更多的步骤以通过中等基线(medium baseline).
    'patience': 300,
}


# 设置随机种子
all_seed(cfg['seed'])
save_path = os.path.join(cfg['save_dir'], cfg['exp_name'])
if not os.path.exists(save_path):
    os.makedirs(save_path, exist_ok=True)

log_path = f"{save_path}/log.txt"
if os.path.exists(log_path):
    os.system(f"rm {log_path}")
# 定义简单的日志方法
log_fw = open(log_path, 'a+') # 打开日志文件保存日志
def log(text):     # 定义一个日志记录函数来跟踪训练过程
    print(text)
    log_fw.write(str(text)+'\n')
    log_fw.flush()

log(cfg)  # 写入配置





# !gdown '1ijKoNmpike_yjUw8SWRVVWVoMOXXqycj' --output food11-hw13.tar.gz


# !ls ../input/ml2022spring-hw13/food11-hw13


for dirname, _, filenames in os.walk('E:\deeplearning_dataset\\food11-hw13'):
    if len(filenames) > 0:
        print(f"{dirname}: {len(filenames)} files.")





normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
# 定义 training/testing transforms
test_tfm = transforms.Compose([
    # 如果你正在使用提供的教师模型(teacher model)，则不建议修改此部分。
    # 下列的transform 方法是标准的，并且足以进行测试。
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    normalize,
])

train_tfm = transforms.Compose([
    # 在这里增加一些有用的transform 或 数据扩增方法, 基于你在HW3中学习的经验
    transforms.Resize(256),  # 你可以修改这里
    transforms.CenterCrop(224), # 你可以修改这里, 但是要注意，给定教师模型(teacher model)的输入大小是224。
    # 因此，除了224之外的输入大小可能会降低模型性能。需要注意。
    transforms.RandomHorizontalFlip(), # 你可以修改这里.
    transforms.ToTensor(),
    normalize,
])


class FoodDataset(Dataset):
    def __init__(self, path, tfm=test_tfm, files=None):
        super().__init__()
        self.path = path
        self.files = sorted([os.path.join(path, i) for i in os.listdir(path) if i.endswith('.jpg')])
        if files is not None:
            self.files = files
        print(f'One {path} sample', self.files[0])
        self.tfm = tfm
    
    def __len__(self):
        return len(self.files)
    
    def __getitem__(self, idx):
        fname = self.files[idx]
        im = Image.open(fname)
        im = self.tfm(im)
        try:
            # label = int(fname.split("/")[-1].split('_')[0])    # windows和liunx文件路径区别
            label = int(fname.split("\\")[-1].split("_")[0])  
        except:
            label = -1
        return im, label



train_set = FoodDataset(os.path.join(cfg['dataset_root'], "training"), tfm=train_tfm)
train_loader = DataLoader(train_set,batch_size=cfg['batch_size'], shuffle=True, num_workers=0, pin_memory=True)

val_set = FoodDataset(os.path.join(cfg['dataset_root'], "validation"), tfm=test_tfm)
val_loader = DataLoader(val_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=0, pin_memory=True)


im, label= train_set.__getitem__(0)
label





# 示例：Depthwise and Pointwise Convlution
def dwpw_conv(in_channels, out_channels, kernel_size, stride=1, padding=0):
    return nn.Sequential(
        nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, groups=in_channels), # depthwise convolution
        nn.Conv2d(in_channels, out_channels, 1) # pointwise convolution
    )





# 在这里定义自己的 student network.
# 我们将使用你的student network来评估您的结果（包括总参数量）

class StudentNetOrg(nn.Module):
    def __init__(self):
        super(StudentNetOrg, self).__init__()
        # TODO: 修改成自己的网络框架
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 32, 3),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Conv2d(32, 32, 3),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),
            
            nn.Conv2d(32, 64, 3),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),
            
            nn.Conv2d(64, 100, 3),
            nn.BatchNorm2d(100),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),
            
            # 在这里，我们对各种输入大小采用全局平均。
            nn.AdaptiveAvgPool2d((1, 1))
        )
        self.fc = nn.Sequential(
            nn.Linear(100, 11)
        )

    def forward(self, x):
        out = self.cnn(x)
        out = out.view(out.size()[0], -1)
        return self.fc(out)


class StudentNet(nn.Module):
    def __init__(self):
        super(StudentNet, self).__init__()
        # TODO: 修改成自己的网络框架
        self.cnn = nn.Sequential(
            dwpw_conv(3, 32, 3, stride=1, padding=0),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            dwpw_conv(32, 32, 3, stride=1, padding=0),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),
            
            dwpw_conv(32, 64, 3, stride=1, padding=0),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),
            
            dwpw_conv(64, 100, 3, stride=1, padding=0),
            nn.BatchNorm2d(100),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),
            
            # 在这里，我们对各种输入大小采用全局平均。
            nn.AdaptiveAvgPool2d((1, 1))
        )
        self.fc = nn.Sequential(
            nn.Linear(100, 11)
        )

    def forward(self, x):
        out = self.cnn(x)
        out = out.view(out.size()[0], -1)
        return self.fc(out)


def get_student_model():
    return StudentNet()





student_model= get_student_model()
student_model_org = StudentNetOrg()
print('**'*35)
print("[ StudentNetOrg ]")
# 输出模型student_model_org的摘要信息，包括每一层的配置（如层的类型、输出形状、参数数量等），
# 以及整个模型的参数总数和可训练参数的数量。
# (3, 224, 224)指定了输入张量的形状，这里表示输入图像的通道数是3（RGB图像），高度和宽度都是224像素
summary(student_model_org,  (3, 224, 224), device='cpu')
print("\n")
print('**'*35)
print("[ StudentNet ]")
summary(student_model, (3, 224, 224), device='cpu')


# 载入提供的教师模型 (restnet18 num_classes=11, test-acc ~= 89.9%)
teacher_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False, num_classes=11)
# load_state dict
teach_ckpt_path = os.path.join(cfg['dataset_root'], "resnet18_teacher.ckpt")
teacher_model.load_state_dict(torch.load(teach_ckpt_path, map_location='cpu'))
summary(teacher_model, (3, 224, 224), device='cpu')








a = torch.randn(4)
a


sft = nn.Softmax(dim=-1)
sft(a), sft(a/1.15), sft(a/0.5), 


# 利用 KL divergence loss 实现知识蒸馏(know distillation)的损失函数 
def loss_fn_kd(student_logits, labels, teacher_logits, alpha=0.5, temperature=1.15):
    # temperature 越大越平滑
    # TODO: 
    kl_loss = torch.nn.KLDivLoss(reduction='mean', log_target=True)
    ce_loss = torch.nn.CrossEntropyLoss(reduction='mean',ignore_index=-1)
    # 创建一个Softmax层，dim=-1表示在最后一个维度上应用Softmax
    sft = nn.Softmax(dim=-1)
    return alpha * temperature * temperature * kl_loss(sft(student_logits/temperature), sft(teacher_logits/temperature)) \
            + (1-alpha) * ce_loss(student_logits, labels)


print("cfg['loss_fn_type']=", cfg['loss_fn_type'])
#  选择损失函数
if cfg['loss_fn_type'] == 'CE':
    loss_fn = nn.CrossEntropyLoss(ignore_index=-1) # simple base line

if cfg['loss_fn_type'] == 'KD':
    loss_fn = loss_fn_kd

# 还可以自定义一些其他方法
device = 'cuda' if torch.cuda.is_available() else 'cpu'
log(f'device: {device}')
device = torch.device(device)
n_epochs = cfg['n_epochs']
patience = cfg['patience']





# 模型初始化，并将参数移入训练设备
student_model.to(device)
opt = torch.optim.Adam(student_model.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])

# 初始化跟踪器, 这部分不是训练参数不需要修改
stale = 0
best_acc = 0.0

teacher_model.to(device)
teacher_model.eval() # MEDIUM BASELINE
for epoch in range(n_epochs):
    # ---------------- Training ----------------------
    # 在训练之前，确保模型是开启训练模式的
    student_model.train()
    # 记录训练过程的信息
    train_loss = []
    train_accs = []
    train_lens = []
    tq_bar = tqdm(train_loader)
    tq_bar.set_description(f"[ Train | Epoch {epoch+1:03d} / {n_epochs:03d} ]")
    for imgs, labels in tq_bar:
        imgs = imgs.to(device)
        labels = labels.to(device)
        # imgs = imgs.half() # 开启半精度。直接可以加快运行速度、减少GPU占用，并且只有不明显的accuracy损失。
        # 前向传播
        with torch.no_grad():  # MEDIUM BASELINE
            teacher_logits = teacher_model(imgs)  # MEDIUM BASELINE
        logits = student_model(imgs)
        # 计算损失.
        loss = loss_fn(logits, labels, teacher_logits)
#         loss = loss_fn(logits, labels)
        opt.zero_grad()
        loss.backward()
        opt.step()
        acc = (logits.argmax(dim=-1) == labels).float().sum()
        # 记录 loss 和 accuracy.
        batch_len = len(imgs)
        train_loss.append(loss.cpu().item() * batch_len)
        train_accs.append(acc)
        train_lens.append(batch_len)
        tq_bar.set_postfix({"loss" : np.mean(train_loss[-10:])})
    
    train_loss = sum(train_loss)/sum(train_lens)
    train_acc = sum(train_accs)/sum(train_lens)
    # 打印信息
    log(f'[ Train | {epoch+1:03d} / {n_epochs:03d} ] loss = {train_loss:.5f} acc = {train_acc:.5f}')
    # ---------------- validation ----------------------
    student_model.eval()
    val_loss = []
    val_accs = []
    val_lens = []
    tq_bar = tqdm(val_loader)
    tq_bar.set_description(f"[ Val | Epoch {epoch+1:03d} / {n_epochs:03d} ]")
    for imgs, labels in tq_bar:
        imgs = imgs.to(device)
        labels = labels.to(device)
        # 前向传播
        with torch.no_grad():  # MEDIUM BASELINE
            teacher_logits = teacher_model(imgs)  # MEDIUM BASELINE
        with torch.no_grad():
            logits = student_model(imgs)
        loss = loss_fn(logits, labels, teacher_logits)
#         loss = loss_fn(logits, labels)
        # 1.使用argmax函数沿着最后一个维度（类别维度）找到最高分数的索引，这将给出预测的类别
        # 2.将预测的类别与真实的标签进行比较，这将返回一个布尔张量，维度为[N]。如果预测正确，相应位置的元素为True，否则为False
        # 3.将布尔张量转换为浮点张量，True变为1.0，False变为0.0
        # 4.计算所有正确预测的总和，这将给出正确预测的数量。这里的sum()默认沿着所有维度进行求和，因此结果是单个数字
        acc = (logits.argmax(dim=-1) == labels).float().sum()
        # 记录 loss 和 accuracy.
        batch_len = len(imgs)
        val_loss.append(loss.cpu().item() * batch_len)
        val_accs.append(acc)
        val_lens.append(batch_len)
        tq_bar.set_postfix({"loss" : np.mean(val_loss[-10:])})
    
    val_loss = sum(val_loss)/sum(val_lens)
    val_acc = sum(val_accs)/sum(val_lens)
    log(f'[ Val | {epoch+1:03d} / {n_epochs:03d} ] loss = {val_loss:.5f} acc = {val_acc:.5f}')
    # 更新logs
    if val_acc > best_acc:
        log(f'Best model found at epoch {epoch+1}. saving model. acc={val_acc:.5f}')
        best_acc = val_acc
        torch.save(student_model.state_dict(), f"{save_path}/student_best.ckpt")
        stale = 0
    else:
        stale += 1
        if (stale > patience):
            log(f'No improving {patience} consecutions. early stopping')
            break
    
log("Finish training")
log_fw.close()





eval_set = FoodDataset(os.path.join(cfg['dataset_root'], "evaluation"), tfm=test_tfm)
eval_loader = DataLoader(eval_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=0, pin_memory=True)


# 载入模型
student_model_best = get_student_model()
ckpt_path = f"{save_path}/student_best.ckpt" 
student_model_best.load_state_dict(torch.load(ckpt_path, map_location='cpu'))
student_model_best.to(device) 

# 开始评估
student_model_best.eval()
eval_preds = [] # storing predictions of the evaluation dataset

for imgs, _ in tqdm(eval_loader):
    # 在eval中不需要进行梯度下降
    with torch.no_grad():
        logits = student_model_best(imgs.to(device))
        # 使用argmax函数沿着最后一个维度（类别维度）找到最高分数的索引，这将给出预测的类别
        # squeeze函数用于移除所有大小为1的维度
        # 这一步是可选的，只有在有额外的单维度时才需要
        # 例如，如果logits的维度是[1, C]或者[N, 1]，那么这一步将分别把形状变为[C]和[N]
        # 将预测类别的张量从GPU移动到CPU（如果它在GPU上）
        # 将张量转换为NumPy数组
        preds = list(logits.argmax(dim=-1).squeeze().cpu().numpy())

    eval_preds += preds

def pad4(i):
    # 一个字符串格式化方法，用于将整数i转换为字符串，并确保该字符串至少有4个字符的长度。
    # 使用zfill方法填充字符串，直到长度为4
    # 如果字符串的长度小于4，那么在左侧填充0
    # 如果字符串的长度已经是4或更长，那么不进行任何填充
    return str(i).zfill(4)

# 保存结果
ids = [pad4(i) for i in range(0, len(eval_set))]
categories = eval_preds

df = pd.DataFrame()
df['Id'] = ids
df['Category'] = categories
df.to_csv(f"submission.csv", index=False) 
